{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Top 50 pairs of Canonical Variables (CCs) between Wav2vec2.0 and GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from brain_encoding.util import scale_and_pca_one_dataset\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import time \n",
    "import numpy as np\n",
    "import pickle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model feature dictionary:\n",
    "    # - Key: GPT-2 XL layer name\n",
    "    # - Value: Feature matrix (shape: [num_words_in_TIMIT, feature_dim])\n",
    "with open(\"../data/gpt2xl_wemb_TIMIT.pkl\", \"rb\") as f:\n",
    "    lg_feat_dict = pickle.load(f)  \n",
    "\n",
    "\n",
    "# Speech model feature dictionary:\n",
    "    # - Key: Wav2Vec2.0 layer name\n",
    "    # - Value: Feature matrix (shape: [num_words_in_TIMIT, feature_dim])\n",
    "    #   - Each row is the mean word embedding over the span of a word\n",
    "with open(\"../data/wav2vec2_mean_wemb_TIMIT.pkl\", \"rb\") as f:\n",
    "    sp_feat_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder7\n",
      "decoder8\n",
      "(3575, 462) (3575, 705)\n",
      "cca_comps: 50\n",
      "CCA consume time: 47.14986062049866 s\n"
     ]
    }
   ],
   "source": [
    "pca_variance_ratio = 0.95 \n",
    "cca_comps = 50\n",
    "sp_ccs_dict, lg_ccs_dict = {}, {}\n",
    "\n",
    "sp_layer_name, lg_layer_name = \"encoder7\", \"decoder8\"  # layer name of speech model and language model\n",
    "\n",
    "sp_stim = sp_feat_dict[sp_layer_name]\n",
    "\n",
    "print(sp_layer_name)\n",
    "\n",
    "lg_stim = lg_feat_dict[lg_layer_name]\n",
    "print(lg_layer_name)\n",
    "\n",
    "sp_stim = scale_and_pca_one_dataset(sp_stim, variance_ratio=pca_variance_ratio, scale=True)\n",
    "lg_stim = scale_and_pca_one_dataset(lg_stim, variance_ratio=pca_variance_ratio, scale=True)\n",
    "\n",
    "print(sp_stim.shape, lg_stim.shape)\n",
    "\n",
    "# cca_comps = min(sp_stim.shape[1], lg_stim.shape[1])\n",
    "print(\"cca_comps:\", cca_comps)\n",
    "\n",
    "cca_st = time.time()\n",
    "my_cca = CCA(n_components=cca_comps, max_iter=20000)\n",
    "\n",
    "# Apply CCA (Canonical Correlation Analysis) to transform the speech and language stimuli. \n",
    "# - 'sp_ccs': Transformed speech features in the CCA space\n",
    "# - 'lg_ccs': Transformed language features in the CCA space\n",
    "# These features ('sp_ccs' and 'lg_ccs') can then be used for neural encoding.\n",
    "sp_ccs, lg_ccs = my_cca.fit_transform(sp_stim, lg_stim)\n",
    "\n",
    "cca_et = time.time()\n",
    "print(\"CCA consume time: {} s\".format(cca_et - cca_st))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
